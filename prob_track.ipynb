{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tractography : probabilistic tracking\n",
    "\n",
    "Considering that the SNR of the measurement is pretty low, and that the information about directions of fascicles that we get in every voxel is not that accurate, we might want to consider this information with a grain of salt. One way to do that is to treat the directions provided by the [reconstruction](DTI.ipynb) [algorithms](SFM.ipynb) as the modes of a probability distribution and, in each iteration of our tracking algorithm, sample from this probability distribution. This also has the benefit that it allows us to track through locations in which the directional signal to the reconstruction algorithms is not as clear, due to SNR issues, or due to spatial and directional resolution of measurement. This approach, pioneered by Behrens et al [1] is called \"probabilistic tractography\". \n",
    "\n",
    "[1] Behrens, T E J, H Johansen-Berg, M W Woolrich, S M Smith, C A M Wheeler-Kingshott, P A Boulby, G J Barker, et al. 2003. “Non-Invasive Mapping of Connections between Human Thalamus and Cortex Using Diffusion Imaging.” Nature Neuroscience 6: 750–57."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import dipy.core.gradients as grad\n",
    "from dipy.data import get_sphere\n",
    "from dipy.reconst.csdeconv import auto_response\n",
    "from dipy.reconst import sfm, dti\n",
    "from dipy.io.trackvis import save_trk\n",
    "from dipy.reconst.peaks import peaks_from_model\n",
    "from dipy.data import small_sphere\n",
    "from dipy.io.trackvis import save_trk\n",
    "from dipy.direction import ProbabilisticDirectionGetter\n",
    "from dipy.tracking.local import ThresholdTissueClassifier\n",
    "from dipy.tracking.local import LocalTracking\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dwi_ni = nib.load(op.join('data', 'SUB1_b2000_1.nii.gz'))\n",
    "LV1_ni = nib.load(op.join('data', 'SUB1_LV1.nii.gz'))\n",
    "labels_ni = nib.load(op.join('data', 'SUB1_aparc-reduced.nii.gz'))\n",
    "\n",
    "data = dwi_ni.get_data()\n",
    "affine = dwi_ni.get_affine()\n",
    "\n",
    "LV1_data = LV1_ni.get_data()\n",
    "labels = labels_ni.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gtab = grad.gradient_table(op.join('data', 'SUB1_b2000_1.bvals'), op.join('data', 'SUB1_b2000_1.bvecs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "white_matter =  (labels == 1) | (labels == 2)\n",
    "V1 = (LV1_data == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response, ratio = auto_response(gtab, data, roi_radius=10, fa_thr=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sphere = get_sphere()\n",
    "sf_model = sfm.SparseFascicleModel(gtab, sphere=sphere,\n",
    "                                   l1_ratio=0.5, alpha=0.001,\n",
    "                                   response=response[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to fit the model in the entire white matter in the following cell, so this might take a little while to run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sf_fit = sf_model.fit(data, mask=white_matter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic tracking requires a mechanism to sample directions from the distribution of directions provided by the model. \n",
    "\n",
    "In this case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fodf = sf_fit.odf(small_sphere)\n",
    "prob_dg = ProbabilisticDirectionGetter.from_pmf(fodf, max_angle=30., sphere=small_sphere)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the determinstic tracking, we need an object that will terminate tracking based on tissue classification. Again, we will use the `TheresholdTissueClassifier` with FA>0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = ThresholdTissueClassifier(white_matter.astype(float), 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll seed the tracking at the pre-defined V1 ROI. We distribute plenty of seeds around V1: 8 in every voxel in the ROI, distributed as `[2, 2, 2]`, that is at a sampling rate of 2x2x2 in each voxel, along each dimension (x/y/z)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.ndimage as ndi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(V1.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ROI resides in the gray matter, so we need to dilate it a little bit into the white matter. This gives as an ROI that contains not only gray matter voxels, but also the white-matter voxels that are adjacent to this part of cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "V1_smoothed = ndi.gaussian_filter(V1.astype(float), sigma=0.25).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.where(V1_smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dipy.tracking import utils\n",
    "seeds = utils.seeds_from_mask(V1_smoothed, density=[2, 2, 2], affine=affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "streamlines = LocalTracking(prob_dg, classifier, seeds, affine, step_size=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to perform the tracking itself. Tracking will be based on all the elements that we have defined so far. In the course of tracking, we will take steps of 0.5 mm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len_th = 10\n",
    "\n",
    "streamlines = [s for s in streamlines if s.shape[0]>len_th]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(streamlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dipy.viz import fvtk\n",
    "from dipy.viz.colormap import line_colors\n",
    "from dipy.data import read_stanford_t1\n",
    "from dipy.tracking.utils import move_streamlines\n",
    "from numpy.linalg import inv\n",
    "t1 = nib.load(op.join('data', 'SUB1_t1_resamp.nii.gz'))\n",
    "t1_data = t1.get_data()\n",
    "t1_aff = t1.get_affine()\n",
    "color = line_colors(streamlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "streamlines_actor = fvtk.streamtube(\n",
    "                    list(move_streamlines(streamlines, inv(t1_aff))),\n",
    "                                    line_colors(streamlines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vol_actor = fvtk.slicer(t1_data, voxsz=(1.0, 1.0, 1.0), plane_i=[40],\n",
    "                        plane_j=None, plane_k=[25], outline=False)\n",
    "\n",
    "ren = fvtk.ren()\n",
    "fvtk.add(ren, streamlines_actor)\n",
    "fvtk.add(ren, vol_actor)\n",
    "fvtk.camera(ren, viewup=(1,0,1), verbose=False)\n",
    "fvtk.record(ren, out_path='prob-track.png', size=(600,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fvtk.show(ren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(Image(filename='prob-track.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_trk(\"prob-track.trk\", streamlines, affine, data.shape[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
