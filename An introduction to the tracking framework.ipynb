{
 "metadata": {
  "name": "",
  "signature": "sha256:deeed2757cd14f60a6462668e9a16fea3a25da035b1304ab97ecc674d0eeda4e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "An introduction to the Tracking Framework"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Local fiber tracking is an approach used to model white matter fibers by\n",
      "creating streamlines from local directional information. The idea is as\n",
      "follows: if the local directionality of a tract/pathway segment is known, one\n",
      "can integrate along those directions to build a complete representation of that\n",
      "structure. Local fiber tracking is widely used in the field of diffusion MRI\n",
      "because it is simple and robust."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to perform local fiber tracking, **three things** are needed:\n",
      "\n",
      "    1. A method for getting directions from a diffusion data set. \n",
      "    2. A method for identifying different tissue types within the data set. \n",
      "    3. A set of seeds from which to begin tracking.  \n",
      "    \n",
      "This example shows how to combine the 3 parts described above to create a tractography reconstruction from a diffusion data set."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "To begin, let's load an example HARDI data set from Stanford. If you have\n",
      "not already downloaded this data set, the first time you run this example you\n",
      "will need to be connected to the internet and this dataset will be downloaded\n",
      "to your computer."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dipy.data import read_stanford_labels\n",
      "\n",
      "hardi_img, gtab, labels_img = read_stanford_labels()\n",
      "data = hardi_img.get_data()\n",
      "labels = labels_img.get_data()\n",
      "affine = hardi_img.get_affine()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dataset is already in place. If you want to fetch it again, please first remove the folder /home/eleftherios/.dipy/stanford_hardi \n",
        "All files already in /home/eleftherios/.dipy/stanford_hardi."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "(81, 106, 76, 160)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "affine"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "array([[   2.,    0.,    0.,  -80.],\n",
        "       [   0.,    2.,    0., -120.],\n",
        "       [   0.,    0.,    2.,  -60.],\n",
        "       [   0.,    0.,    0.,    1.]])"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "This dataset provides a ``label map`` (freesurfer labels) in which all white matter tissues are\n",
      "labeled either 1 or 2. Lets create a white matter mask to restrict tracking to\n",
      "the white matter."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "white_matter = (labels == 1) | (labels == 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1. Getting the directions from a Reconstruction Model (dipy.reconst)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "The first thing we need to begin fiber tracking is a way of getting\n",
      "directions from this diffusion data set. In order to do that, we can fit the\n",
      "data to a ``Constant Solid Angle ODF Model`` (a type of QBall by Aganj et.al). This is the reconstruction step.\n",
      "\n",
      "This model will estimate the orientation distribution function (ODF) at each voxel. \n",
      "\n",
      "The ODF is the distribution of water diffusion as a function of direction. The peaks of an ODF\n",
      "are good estimates for the orientation of tract segments at a point in the image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dipy.reconst.shm import CsaOdfModel\n",
      "csa_model = CsaOdfModel(gtab, sh_order=6)\n",
      "# csa_fit = csa_model.fit(data, mask)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "We can then use ``peaks_from_model`` to call the fit with a specific parallelization.\n",
      "Notice that this function acts like a hub for all reconstruction models."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dipy.data import default_sphere\n",
      "from dipy.direction import peaks_from_model\n",
      "csa_peaks = peaks_from_model(csa_model, data, default_sphere,\n",
      "                             relative_peak_threshold=.8,\n",
      "                             min_separation_angle=45,\n",
      "                             mask=white_matter)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "csa_peaks.peak_dirs.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "(81, 106, 76, 5, 3)"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2. Finding where to stop tracking by looking into different tissue types"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Next we need some way of restricting the fiber tracking to areas with good\n",
      "directionality information. We've already created the white matter mask,\n",
      "but we can go a step further and restrict fiber tracking to those areas where\n",
      "the ODF shows significant restricted diffusion by thresholding on\n",
      "the general fractional anisotropy (GFA).\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dipy.tracking.local import ThresholdTissueClassifier\n",
      "\n",
      "classifier = ThresholdTissueClassifier(csa_peaks.gfa, .25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3. Specify where to \"seed\" (begin) fiber tracking"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Generally, the seeds chosen will depend on the pathways one is\n",
      "interested in modeling. In this example, we'll use a 2x2x2 grid of seeds per\n",
      "voxel, in a sagittal slice of the Corpus Callosum.  Tracking from this region\n",
      "will give us a model of the Corpus Callosum tract.  This slice has label value\n",
      "2 in the labels image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dipy.tracking import utils\n",
      "\n",
      "seed_mask = labels == 2\n",
      "seeds = utils.seeds_from_mask(seed_mask, density=[2, 2, 2], affine=affine)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Bring everything together using LocalTracking"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dipy.tracking.local import LocalTracking\n",
      "\n",
      "# Initialization of LocalTracking. The computation happens in the next step.\n",
      "streamlines_generator = LocalTracking(csa_peaks, classifier, seeds, affine, step_size=.5)\n",
      "\n",
      "# Compute streamlines and store as a list.\n",
      "streamlines = list(streamlines_generator)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "We will then display the resulting streamlines using the ``dipy.viz`` module."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dipy.viz import fvtk\n",
      "from dipy.viz.colormap import line_colors\n",
      "\n",
      "# Prepare the display objects.\n",
      "color = line_colors(streamlines)\n",
      "streamlines_actor = fvtk.line(streamlines, line_colors(streamlines), linewidth=1.5)\n",
      "\n",
      "# Create the 3d display.\n",
      "scene = fvtk.ren()\n",
      "fvtk.add(scene, streamlines_actor)\n",
      "\n",
      "# Save still images for this static example. Or for interactivity use fvtk.show\n",
      "fvtk.record(scene, n_frames=1, out_path='deterministic.png',\n",
      "            size=(800, 800))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fvtk.show(scene, size=(800, 800))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "We've created a deterministic set of streamlines, so called because if you\n",
      "repeat the fiber tracking (keeping all the inputs the same) you will get\n",
      "exactly the same set of streamlines. We can save the streamlines as a Trackvis\n",
      "file so it can be loaded into other software for visualization or further\n",
      "analysis."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dipy.io.trackvis import save_trk\n",
      "save_trk(\"CSA_detr.trk\", streamlines, affine, labels.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Rewind with CSD and Probabilistic Tracking"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Next let's try some probabilistic fiber tracking. For this, we'll be using the\n",
      "``Constrained Spherical Deconvolution (CSD) Model``. This model represents each\n",
      "voxel in the data set as a collection of small white matter fibers with\n",
      "different orientations. The density of fibers along each orientation is known\n",
      "as the Fiber Orientation Distribution (FOD). In order to perform probabilistic\n",
      "fiber tracking, we pick a fiber from the FOD at random at each new location\n",
      "along the streamline. Note: one could use this model to perform deterministic\n",
      "fiber tracking by always tracking along the directions that have the most\n",
      "fibers.\n",
      "\n",
      "Let's begin probabilistic fiber tracking by fitting the data to the CSD model."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dipy.reconst.csdeconv import (ConstrainedSphericalDeconvModel,\n",
      "                                   auto_response)\n",
      "\n",
      "response, ratio = auto_response(gtab, data, roi_radius=10, fa_thr=0.7)\n",
      "csd_model = ConstrainedSphericalDeconvModel(gtab, response, sh_order=6)\n",
      "csd_fit = csd_model.fit(data, mask=white_matter)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Next we'll need to make a ``ProbabilisticDirectionGetter``. Because the CSD\n",
      "model represents the FOD using the spherical harmonic basis, we can use the\n",
      "``from_shcoeff`` method to create the direction getter. This direction getter\n",
      "will randomly sample directions from the FOD each time the tracking algorithm\n",
      "needs to take another step."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from dipy.direction import ProbabilisticDirectionGetter\n",
      "\n",
      "prob_dg = ProbabilisticDirectionGetter.from_shcoeff(csd_fit.shm_coeff,\n",
      "                                                    max_angle=30.,\n",
      "                                                    sphere=default_sphere)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "As with deterministic tracking, we'll need to use a tissue classifier to\n",
      "restrict the tracking to the white matter of the brain. One might be tempted\n",
      "to use the GFA of the CSD FODs to build a tissue classifier, however the GFA\n",
      "values of these FODs don't classify gray matter and white matter well. We will\n",
      "therefore use the GFA from the CSA model which we fit for the first section of\n",
      "this example. Alternatively, one could fit a ``TensorModel`` to the data and use\n",
      "the fractional anisotropy (FA) to build a tissue classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classifier = ThresholdTissueClassifier(csa_peaks.gfa, .25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Next we can pass this direction getter, along with the ``classifier`` and\n",
      "``seeds``, to ``LocalTracking`` to get a probabilistic model of the corpus\n",
      "callosum."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "streamlines = LocalTracking(prob_dg, classifier, seeds, affine,\n",
      "                            step_size=.5, max_cross=1)\n",
      "\n",
      "# Compute streamlines and store as a list.\n",
      "streamlines = list(streamlines)\n",
      "\n",
      "# Prepare the display objects.\n",
      "color = line_colors(streamlines)\n",
      "streamlines_actor = fvtk.line(streamlines, line_colors(streamlines))\n",
      "\n",
      "# Create the 3d display.\n",
      "scene = fvtk.ren()\n",
      "fvtk.add(scene, streamlines_actor)\n",
      "\n",
      "# Save still images for this static example.\n",
      "fvtk.record(scene, n_frames=1, out_path='probabilistic.png',\n",
      "            size=(800, 800))\n",
      "\n",
      "save_trk(\"CSD_prob.trk\", streamlines, affine, labels.shape)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fvtk.show(scene, size=(800, 800))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!eog probabilistic.png deterministic.png"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}